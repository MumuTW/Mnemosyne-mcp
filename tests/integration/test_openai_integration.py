#!/usr/bin/env python
"""
OpenAI API æ•´åˆæ¸¬è©¦

æ¸¬è©¦çœŸå¯¦çš„ OpenAI API æ•´åˆï¼Œé©—è­‰ä¸‰å€‹æ ¸å¿ƒ LLM èƒ½åŠ›ã€‚
"""

import asyncio
import os
import sys
import time

# æ·»åŠ è·¯å¾‘
worktree_path = "/Users/johnson/Documents/project/worktree-ai-agent-integration"
src_path = os.path.join(worktree_path, "src")
sys.path.insert(0, src_path)

try:
    from mnemosyne.llm.providers.openai_provider import OpenAIProvider

    print("âœ… OpenAI Provider modules imported successfully")
except ImportError as e:
    print(f"âŒ Import error: {e}")
    sys.exit(1)


class OpenAIIntegrationTest:
    """OpenAI API æ•´åˆæ¸¬è©¦å¥—ä»¶"""

    def __init__(self):
        self.provider = None

    async def setup(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        print("ğŸ”§ Setting up OpenAI integration test environment...")

        # æª¢æŸ¥ API Key
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            print("  âš ï¸ OPENAI_API_KEY not found in environment variables")
            print("  ğŸ“ Will test in mock mode")
            self.provider = OpenAIProvider()
        else:
            print("  âœ… OPENAI_API_KEY found")
            self.provider = OpenAIProvider({"api_key": api_key})

        # åˆå§‹åŒ– provider
        try:
            await self.provider.initialize()
            print("  âœ… OpenAI Provider initialized")
        except Exception as e:
            print(f"  âš ï¸ Provider initialization failed: {e}")
            print("  ğŸ“ Will test basic functionality only")

    async def test_generate_text(self):
        """æ¸¬è©¦æ–‡æœ¬ç”ŸæˆåŠŸèƒ½"""
        print("\nğŸ§  Testing text generation with gpt-4o-mini...")

        test_prompts = [
            "Explain what is artificial intelligence in one sentence.",
            "Write a simple Python function to calculate factorial.",
        ]

        results = []

        for i, prompt in enumerate(test_prompts, 1):
            print(f"  ğŸ“¤ Test {i}: '{prompt[:50]}...'")

            start_time = time.time()

            try:
                response = await self.provider.generate_text(
                    prompt=prompt, max_tokens=100, temperature=0.7
                )

                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # ms

                print(f"    ğŸ“¥ Response time: {response_time:.2f}ms")
                print(f"    ğŸ“ Content: {response.content[:100]}...")
                print(f"    ğŸ“Š Usage: {response.usage}")

                # æª¢æŸ¥æ˜¯å¦æ˜¯æ¨¡æ“¬éŸ¿æ‡‰
                is_mock = response.metadata and response.metadata.get("mode") == "mock"
                if is_mock:
                    print("    âš ï¸ Mock response (API not available)")
                else:
                    print("    âœ… Real API response")

                results.append(
                    {
                        "test": f"generate_text_{i}",
                        "response_time_ms": response_time,
                        "is_mock": is_mock,
                        "success": True,
                    }
                )

            except Exception as e:
                print(f"    âŒ Generation failed: {e}")
                results.append(
                    {"test": f"generate_text_{i}", "success": False, "error": str(e)}
                )

        return results

    async def test_capabilities(self):
        """æ¸¬è©¦ Provider èƒ½åŠ›"""
        print("\nğŸ” Testing provider capabilities...")

        try:
            capabilities = self.provider.supported_capabilities
            print(f"  âœ… Supported capabilities: {[cap.value for cap in capabilities]}")
            return [{"test": "capabilities", "success": True}]
        except Exception as e:
            print(f"  âŒ Capabilities test failed: {e}")
            return [{"test": "capabilities", "success": False, "error": str(e)}]

    async def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰ OpenAI æ•´åˆæ¸¬è©¦"""
        print("ğŸš€ Starting OpenAI API Integration Tests...")
        print("=" * 70)

        await self.setup()

        # é‹è¡Œå„é …æ¸¬è©¦
        text_results = await self.test_generate_text()
        capability_results = await self.test_capabilities()

        # å½™ç¸½çµæœ
        all_results = text_results + capability_results

        # çµ±è¨ˆ
        total_tests = len(all_results)
        successful_tests = len([r for r in all_results if r.get("success", False)])
        failed_tests = total_tests - successful_tests

        # è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“
        response_times = [
            r.get("response_time_ms", 0)
            for r in all_results
            if r.get("response_time_ms")
        ]
        avg_response_time = (
            sum(response_times) / len(response_times) if response_times else 0
        )

        # æª¢æŸ¥æ˜¯å¦æœ‰çœŸå¯¦ API èª¿ç”¨
        real_api_calls = len(
            [
                r
                for r in text_results
                if r.get("success") and not r.get("is_mock", False)
            ]
        )

        summary = {
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "failed_tests": failed_tests,
            "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
            "average_response_time_ms": avg_response_time,
            "real_api_calls": real_api_calls,
        }

        return summary


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ OpenAI API Integration Test Suite")
    print("Testing gpt-4o-mini model integration")
    print("=" * 70)

    test_suite = OpenAIIntegrationTest()

    try:
        results = await test_suite.run_all_tests()

        # æ‰“å°æ¸¬è©¦çµæœæ‘˜è¦
        print("\nğŸ“Š OpenAI Integration Test Results Summary:")
        print("=" * 70)

        print("ğŸ“ˆ Test Statistics:")
        print(f"  â€¢ Total tests: {results['total_tests']}")
        print(f"  â€¢ Successful: {results['successful_tests']}")
        print(f"  â€¢ Failed: {results['failed_tests']}")
        print(f"  â€¢ Success rate: {results['success_rate']:.1%}")

        if results["average_response_time_ms"] > 0:
            print(
                f"  â€¢ Average response time: {results['average_response_time_ms']:.2f}ms"
            )

        print("\nğŸ”— API Integration Status:")
        if results["real_api_calls"] > 0:
            print(f"  âœ… Real OpenAI API calls successful: {results['real_api_calls']}")
            print("  ğŸš€ OpenAI integration is working correctly")
        else:
            print("  âš ï¸ No real API calls made (likely missing API key)")
            print("  ğŸ“ Tests ran in mock/fallback mode")

        # æ•´é«”è©•ä¼°
        if results["success_rate"] >= 0.8:
            print("\nğŸ‰ OpenAI Integration Test Suite PASSED!")
            return 0
        else:
            print("\nâŒ OpenAI Integration Test Suite FAILED!")
            return 1

    except Exception as e:
        print(f"\nâŒ OpenAI Integration Test Suite crashed: {e}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
